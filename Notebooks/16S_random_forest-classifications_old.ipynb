{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16S Random Forest Classifier\n",
    "\n",
    "### Objective:\n",
    "Use genus-level 16S V4 rRNA amplicon sequencing data to train a Random Forest classifier\n",
    "that predicts skin condition type (healthy, acne non-lesional, or acne lesional)\n",
    "based on skin, nose, and skin + nose bacterial abundance profiles.\n",
    "\n",
    "Inputs:\n",
    "- 16S-level microbial feature tables (absolute abundance CLR transformed)\n",
    "\n",
    "Outputs:\n",
    "- Predicted skin condition label per sample\n",
    "\n",
    "Goals:\n",
    "1. Evaluate classification performance for skin AD L vs H, skin AD NL vs H, skin AD NL vs AD L: We would expect AD L vs H to likely have the best model performance, followed by AD NL vs H, then AD NL vs L. What are the driving taxa which contribute to classification of feature importance by each model?\n",
    "2. Evaluate classification performance for nares AD positive vs AD negative: Can the model predict AD condition based on nares samples alone? This would be interesting. Driving taxa?\n",
    "3. If 1 and 2 look pretty good, evaluate classification performance combining skin and nares samples improves classification performance further. If true, this would be very interesting. \n",
    "\n",
    "### Things to note:\n",
    "- Use absolute abundance with center log ratio (CLR) transformation with a small pseudocount (see function below) (not relative abundance, and not relative abundance and absolute concatenated).\n",
    "- Be cautious about class imbalance: All samples from a single person should be entirely in the training set OR entirely in the test set — never split across both. Currently, the random splitting means there are going to be samples from the same person in both groups. This can superinflate results because your model can essentially \"cheat\" by learning person-specific features rather than what truly distinguishes classes like lesional vs. non-lesional. See code below from sklearn.model_selection import GroupShuffleSplit.\n",
    "- It may be better to use ASV level features rather than Genera-level collapsed features (but we can discuss this later if needed).\n",
    "- I'm no expert in ML, so use online resources ;)\n",
    "\n",
    "### Visualization outcomes:\n",
    "- A ROC curve graph with 3 lines of different colors, skin AD L vs H, AD NL vs H, AD NL vs L. Show Area Under Curve (AUC) values for each binary classification.\n",
    "- A ROC curve graph with 2 lines of different colors, nares AD vs nares healthy control. Show Area Under Curve (AUC) values for the binary classification.\n",
    "- Perhaps some horizontal barplots to show features which highest classification performance for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import warnings\n",
    "import logging\n",
    "from itertools import combinations\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "import scipy\n",
    "import scipy.stats as ss\n",
    "from scipy import interp\n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-bio\n",
    "from skbio.stats.distance import permanova\n",
    "\n",
    "# BIOM format\n",
    "import biom\n",
    "from biom import load_table\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_curve, auc, RocCurveDisplay\n",
    ")\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import label_binarize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_convert_biom(biom_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a BIOM-format table and convert it into a Pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    biom_path (str): The file path to the biom table.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The dataframe corresponding to the biom table.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Loading BIOM file: {biom_path}\")\n",
    "    try:\n",
    "        biom_table = load_table(biom_path)\n",
    "        df = pd.DataFrame(biom_table.to_dataframe().T)\n",
    "        logging.info(f\"BIOM table shape: {df.shape}\")\n",
    "        logging.info(\"BIOM file successfully converted to DataFrame\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in processing BIOM file: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clr_transform_with_pseudocount(df, pseudocount=1e-6, use_inf=False):\n",
    "    \"\"\"\n",
    "    Applies Centered Log-Ratio (CLR) transformation to a DataFrame of abundance data.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "        Microbial abundance table (samples as rows, features as columns).\n",
    "    - pseudocount: float\n",
    "        Small constant to add to avoid log(0). Default is 1e-6.\n",
    "\n",
    "    Returns:\n",
    "    - clr_df: pandas DataFrame\n",
    "        CLR-transformed DataFrame.\n",
    "    \"\"\"\n",
    "    # Add pseudocount\n",
    "    df_pseudo = df + pseudocount\n",
    "\n",
    "    # Take the natural log\n",
    "    log_df = np.log(df_pseudo)\n",
    "\n",
    "    if not use_inf:\n",
    "        # Subtract geometric mean per sample (i.e., row-wise)\n",
    "        clr_values = log_df.subtract(log_df.mean(axis=1), axis=0)\n",
    "\n",
    "    else:\n",
    "        # the log values could be -inf, so we won't take them into the mean calculation, but put them back to -inf\n",
    "        # replace -inf with nan\n",
    "        log_df = log_df.replace(-6, np.nan)\n",
    "        log_mean = log_df.apply(np.nanmean, axis=1) # maybe slow?\n",
    "        clr_values = log_df.subtract(log_mean, axis=0)\n",
    "        clr_values = clr_values.fillna(-np.inf)\n",
    "\n",
    "    return clr_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_abundance(df):\n",
    "    \"\"\"\n",
    "    Convert a DataFrame of absolute abundances to relative abundances.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "        Microbial abundance table (samples as rows, features as columns).\n",
    "\n",
    "    Returns:\n",
    "    - rel_df: pandas DataFrame\n",
    "        Relative abundance table (samples as rows, features as columns).\n",
    "    \"\"\"\n",
    "    return df.div(df.sum(axis=1), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(X_clr, y, train_idx, test_idx, y_train, y_test, groups, case_types):\n",
    "    train_idx_filtered = train_idx[y_train.isin(case_types)]\n",
    "    test_idx_filtered = test_idx[y_test.isin(case_types)]\n",
    "\n",
    "    X_train_filtered = X_clr.iloc[train_idx_filtered]\n",
    "    X_test_filtered = X_clr.iloc[test_idx_filtered]\n",
    "    y_train_filtered = y.iloc[train_idx_filtered]\n",
    "    y_test_filtered = y.iloc[test_idx_filtered]\n",
    "\n",
    "    print(f\"Training set size: {X_train_filtered.shape[0]} samples (original: {len(X_train)})\")\n",
    "    print(f\"Testing set size: {X_test_filtered.shape[0]} samples (original: {len(X_test)})\")\n",
    "\n",
    "    assert set(groups[y_train_filtered.index]) & set(groups[y_test_filtered.index]) == set(), \"Participant leakage detected!\"\n",
    "    return X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATTTATTGGGCGTAAAGCGAGCGCAGGCGGTTAGATAAGTCTGAAGTTAAAGGCTG</th>\n",
       "      <th>GTGCCAGCCGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATTTATTGGGCGTAAAGCGAGCGCAGGCGGTTAGATAAGTCTGAAGTTAAAGGCTG</th>\n",
       "      <th>GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAATTACTGGGCGTAAAGAGCTCGTAGGTGGTTTGTCACGTCGTCTGTGAAATTCCA</th>\n",
       "      <th>GTGCCAGCCGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAATTACTGGGCGTAAAGAGCTCGTAGGTGGTTTGTCACGTCGTCTGTGAAATTCCA</th>\n",
       "      <th>GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTAATCGGAATTATTGGGCGTAAAGCGAGTGCAGACGGTTACTTAAGCCAGATGTGAAATCCCC</th>\n",
       "      <th>GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAATTATTGGGCGTAAAGCGCGCGCAGGCGGTTTCTTAAGTCTGATGTGAAAGCCCC</th>\n",
       "      <th>GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATTTATTGGGCGTAAAGGGCTCGTAGGTGGTTGATCGCGTCGGAAGTGTAATCTTG</th>\n",
       "      <th>GTGCCAGCAGCCGCGGTAATACGTAGGGTCCAAGCGTTAATCGGAATTACTGGGCGTAAAGCGTGCGCAGGCGGTTGTGCAAGACCGATGTGAAATCCCC</th>\n",
       "      <th>GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGATTTATTGGGCGTAAAGGGAGCGCAGGTGGTTTCTTAAGTCTGATGTGAAAGCCCA</th>\n",
       "      <th>GTGCCAGCCGCCGCGGTAATACGGAAGGTCCAGGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGGCGGATTATTAAGTCAGTGGTGAAAGACGG</th>\n",
       "      <th>...</th>\n",
       "      <th>GTGCCAGCCGCCGCGGTAATACGTAGGGGGCAAGCGTTATCCGGATTTACTGGGTGTAAAGGGAGCGTAGACGGCGCAGCAAGTCTGATGTGAAAGGCAG</th>\n",
       "      <th>GTGCCAGCAGCCGCGGTAAGACAGAGGGTGCAAACGTTGCTCGGAATCACTGGGCGTAAAGGGCGTGTAGGCGGGAGAGAAAGTCGGGCGTGAAATCCCT</th>\n",
       "      <th>GTGCCAGCCGCGGTAATACGTAGGGGGCTAGCGTTGTCCGGAATCACTGGGCGTAAAGGGTTCGCAGGCGGAAATGCAAGTCAGGTGTAAAAGGCAGTAG</th>\n",
       "      <th>GTGCCAGCAGCCGCGGTAATACGTAGGGCGCGAGCGTTGTCCGGAATTATTGGGCGTAAAGAGCTTGTAGGCGGTTTGTTGCGTCTGCTGTGAAAGACCG</th>\n",
       "      <th>GTGCCAGCCGCCGCGGTAATACGTAGGGCGCGAGCGTTGTCCGGAATTATTGGGCGTAAAGAGCTTGTAGGCGGTTTGTTGCGTCTGCTGTGAAAGACCG</th>\n",
       "      <th>GTGCCAGCAGCCGCGGTAATACGGAGGGTGCAAGCGTTATCCGGAATCATTGGGTTTAAAGGGTCCGCAGGCGGATTTATAAGTCAGTGGTGAAAGCCTA</th>\n",
       "      <th>GTGCCAGCAGCCGCGGTAATACGTAGGTGGCGAGCGTTGTCCGGAATTACTGGGTGTAAAGGGCGTGTAGGCGGGAAGGTAAGTCAGATGTGAAATACCG</th>\n",
       "      <th>GTGCCAGCCGCCGCGGTAATACGGAGGATGCGAGCGTTATTCGGAATCATTGGGTTTAAAGGGTCTGTAGGCGGGCTATTAAGTCAGAGGTGAAAGGTTT</th>\n",
       "      <th>GTGCCAGCCGCCGCGGTAAGACGAAGGGGGCTAGCGTTGTTCGGAATTACTGGGCGTAAAGCGCGTGCAGGCGGTTATCCAAGTCGGGTGTGAAAGCCTT</th>\n",
       "      <th>GTCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATTTATTGGGCGTAAAGCGAGCGCAGGCGGTTAGATAAGTCTGAAGTTAAAGGCTGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>900344</th>\n",
       "      <td>984.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900459</th>\n",
       "      <td>118.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900221</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900570</th>\n",
       "      <td>389.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900092</th>\n",
       "      <td>3106.0</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9003972</th>\n",
       "      <td>1168.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900097</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900498</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900276</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900406</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 2283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATTTATTGGGCGTAAAGCGAGCGCAGGCGGTTAGATAAGTCTGAAGTTAAAGGCTG  \\\n",
       "900344                                               984.0                                                      \n",
       "900459                                               118.0                                                      \n",
       "900221                                                22.0                                                      \n",
       "900570                                               389.0                                                      \n",
       "900092                                              3106.0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                             1168.0                                                      \n",
       "900097                                                24.0                                                      \n",
       "900498                                                15.0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCCGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATTTATTGGGCGTAAAGCGAGCGCAGGCGGTTAGATAAGTCTGAAGTTAAAGGCTG  \\\n",
       "900344                                               611.0                                                      \n",
       "900459                                               106.0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                              1707.0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                              593.0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                17.0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAATTACTGGGCGTAAAGAGCTCGTAGGTGGTTTGTCACGTCGTCTGTGAAATTCCA  \\\n",
       "900344                                               114.0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                59.0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                               16.0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                30.0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCCGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAATTACTGGGCGTAAAGAGCTCGTAGGTGGTTTGTCACGTCGTCTGTGAAATTCCA  \\\n",
       "900344                                                82.0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                32.0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTAATCGGAATTATTGGGCGTAAAGCGAGTGCAGACGGTTACTTAAGCCAGATGTGAAATCCCC  \\\n",
       "900344                                                22.0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                 8.0                                                      \n",
       "900092                                                 3.0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                               28.0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAATTATTGGGCGTAAAGCGCGCGCAGGCGGTTTCTTAAGTCTGATGTGAAAGCCCC  \\\n",
       "900344                                                15.0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATTTATTGGGCGTAAAGGGCTCGTAGGTGGTTGATCGCGTCGGAAGTGTAATCTTG  \\\n",
       "900344                                                 8.0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                16.0                                                      \n",
       "900570                                                11.0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                              736.0                                                      \n",
       "900097                                                33.0                                                      \n",
       "900498                                                34.0                                                      \n",
       "900276                                               151.0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCAGCCGCGGTAATACGTAGGGTCCAAGCGTTAATCGGAATTACTGGGCGTAAAGCGTGCGCAGGCGGTTGTGCAAGACCGATGTGAAATCCCC  \\\n",
       "900344                                                 8.0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGATTTATTGGGCGTAAAGGGAGCGCAGGTGGTTTCTTAAGTCTGATGTGAAAGCCCA  \\\n",
       "900344                                                 6.0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                14.0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCCGCCGCGGTAATACGGAAGGTCCAGGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGGCGGATTATTAAGTCAGTGGTGAAAGACGG  \\\n",
       "900344                                                 3.0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                 7.0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                               36.0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         ...  \\\n",
       "900344   ...   \n",
       "900459   ...   \n",
       "900221   ...   \n",
       "900570   ...   \n",
       "900092   ...   \n",
       "...      ...   \n",
       "9003972  ...   \n",
       "900097   ...   \n",
       "900498   ...   \n",
       "900276   ...   \n",
       "900406   ...   \n",
       "\n",
       "         GTGCCAGCCGCCGCGGTAATACGTAGGGGGCAAGCGTTATCCGGATTTACTGGGTGTAAAGGGAGCGTAGACGGCGCAGCAAGTCTGATGTGAAAGGCAG  \\\n",
       "900344                                                   0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                 8.0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCAGCCGCGGTAAGACAGAGGGTGCAAACGTTGCTCGGAATCACTGGGCGTAAAGGGCGTGTAGGCGGGAGAGAAAGTCGGGCGTGAAATCCCT  \\\n",
       "900344                                                   0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                 5.0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCCGCGGTAATACGTAGGGGGCTAGCGTTGTCCGGAATCACTGGGCGTAAAGGGTTCGCAGGCGGAAATGCAAGTCAGGTGTAAAAGGCAGTAG  \\\n",
       "900344                                                   0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                 1.0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCAGCCGCGGTAATACGTAGGGCGCGAGCGTTGTCCGGAATTATTGGGCGTAAAGAGCTTGTAGGCGGTTTGTTGCGTCTGCTGTGAAAGACCG  \\\n",
       "900344                                                   0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                15.0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCCGCCGCGGTAATACGTAGGGCGCGAGCGTTGTCCGGAATTATTGGGCGTAAAGAGCTTGTAGGCGGTTTGTTGCGTCTGCTGTGAAAGACCG  \\\n",
       "900344                                                   0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                10.0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCAGCCGCGGTAATACGGAGGGTGCAAGCGTTATCCGGAATCATTGGGTTTAAAGGGTCCGCAGGCGGATTTATAAGTCAGTGGTGAAAGCCTA  \\\n",
       "900344                                                   0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                 8.0                                                      \n",
       "900276                                                   0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCAGCCGCGGTAATACGTAGGTGGCGAGCGTTGTCCGGAATTACTGGGTGTAAAGGGCGTGTAGGCGGGAAGGTAAGTCAGATGTGAAATACCG  \\\n",
       "900344                                                   0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                11.0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCCGCCGCGGTAATACGGAGGATGCGAGCGTTATTCGGAATCATTGGGTTTAAAGGGTCTGTAGGCGGGCTATTAAGTCAGAGGTGAAAGGTTT  \\\n",
       "900344                                                   0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                 3.0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTGCCAGCCGCCGCGGTAAGACGAAGGGGGCTAGCGTTGTTCGGAATTACTGGGCGTAAAGCGCGTGCAGGCGGTTATCCAAGTCGGGTGTGAAAGCCTT  \\\n",
       "900344                                                   0                                                      \n",
       "900459                                                   0                                                      \n",
       "900221                                                   0                                                      \n",
       "900570                                                   0                                                      \n",
       "900092                                                   0                                                      \n",
       "...                                                    ...                                                      \n",
       "9003972                                                  0                                                      \n",
       "900097                                                   0                                                      \n",
       "900498                                                   0                                                      \n",
       "900276                                                 2.0                                                      \n",
       "900406                                                   0                                                      \n",
       "\n",
       "         GTCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATTTATTGGGCGTAAAGCGAGCGCAGGCGGTTAGATAAGTCTGAAGTTAAAGGCTGT  \n",
       "900344                                                   0                                                     \n",
       "900459                                                   0                                                     \n",
       "900221                                                   0                                                     \n",
       "900570                                                   0                                                     \n",
       "900092                                                   0                                                     \n",
       "...                                                    ...                                                     \n",
       "9003972                                                  0                                                     \n",
       "900097                                                   0                                                     \n",
       "900498                                                   0                                                     \n",
       "900276                                                 1.0                                                     \n",
       "900406                                                   0                                                     \n",
       "\n",
       "[502 rows x 2283 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in table at ASV level\n",
    "biom_path = '..//Data/Tables/Absolute_Abundance_Tables/209766_filtered_feature_table.biom'\n",
    "biom_tbl = load_table(biom_path)\n",
    "df = pd.DataFrame(biom_tbl.to_dataframe().T)\n",
    "\n",
    "# delete the prefix from the index\n",
    "df.index = df.index.str.replace('15564.', '')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlateNumber</th>\n",
       "      <th>PlateLocation</th>\n",
       "      <th>i5</th>\n",
       "      <th>i5Sequence</th>\n",
       "      <th>i7</th>\n",
       "      <th>i7Sequence</th>\n",
       "      <th>identifier</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Plate ID</th>\n",
       "      <th>Well location</th>\n",
       "      <th>...</th>\n",
       "      <th>sex</th>\n",
       "      <th>enrolment_date</th>\n",
       "      <th>enrolment_season</th>\n",
       "      <th>hiv_exposure</th>\n",
       "      <th>hiv_status</th>\n",
       "      <th>household_size</th>\n",
       "      <th>o_scorad</th>\n",
       "      <th>FWD_filepath</th>\n",
       "      <th>REV_filepath</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#sample-id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ca009STL</th>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>SA501</td>\n",
       "      <td>ATCGTACG</td>\n",
       "      <td>SA701</td>\n",
       "      <td>CGAGAGTT</td>\n",
       "      <td>SA701SA501</td>\n",
       "      <td>CGAGAGTT-ATCGTACG</td>\n",
       "      <td>1.010000e+21</td>\n",
       "      <td>A1</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>4/16/2015</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Unexposed</td>\n",
       "      <td>negative</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>skin-ADL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900221</th>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>SA502</td>\n",
       "      <td>ACTATCTG</td>\n",
       "      <td>SA701</td>\n",
       "      <td>CGAGAGTT</td>\n",
       "      <td>SA701SA502</td>\n",
       "      <td>CGAGAGTT-ACTATCTG</td>\n",
       "      <td>1.010000e+21</td>\n",
       "      <td>B1</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>8/11/2015</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Unexposed</td>\n",
       "      <td>negative</td>\n",
       "      <td>7.0</td>\n",
       "      <td>34</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>skin-ADL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ca010EBL</th>\n",
       "      <td>1</td>\n",
       "      <td>C1</td>\n",
       "      <td>SA503</td>\n",
       "      <td>TAGCGAGT</td>\n",
       "      <td>SA701</td>\n",
       "      <td>CGAGAGTT</td>\n",
       "      <td>SA701SA503</td>\n",
       "      <td>CGAGAGTT-TAGCGAGT</td>\n",
       "      <td>1.010000e+21</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>11/20/2014</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Unexposed</td>\n",
       "      <td>negative</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>skin-ADL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900460</th>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "      <td>SA504</td>\n",
       "      <td>CTGCGTGT</td>\n",
       "      <td>SA701</td>\n",
       "      <td>CGAGAGTT</td>\n",
       "      <td>SA701SA504</td>\n",
       "      <td>CGAGAGTT-CTGCGTGT</td>\n",
       "      <td>1.010000e+21</td>\n",
       "      <td>D1</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>9/23/2015</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Unexposed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>skin-ADL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900051</th>\n",
       "      <td>1</td>\n",
       "      <td>E1</td>\n",
       "      <td>SA505</td>\n",
       "      <td>TCATCGAG</td>\n",
       "      <td>SA701</td>\n",
       "      <td>CGAGAGTT</td>\n",
       "      <td>SA701SA505</td>\n",
       "      <td>CGAGAGTT-TCATCGAG</td>\n",
       "      <td>1.010000e+21</td>\n",
       "      <td>E1</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>4/21/2015</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Unexposed</td>\n",
       "      <td>negative</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>skin-ADL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ca006ONL2</th>\n",
       "      <td>6</td>\n",
       "      <td>H1</td>\n",
       "      <td>SA508</td>\n",
       "      <td>GACACCGT</td>\n",
       "      <td>SB701</td>\n",
       "      <td>CTCGACTT</td>\n",
       "      <td>SB701SA508</td>\n",
       "      <td>CTCGACTT-GACACCGT</td>\n",
       "      <td>1.010000e+21</td>\n",
       "      <td>H1</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>3/25/2015</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Unexposed</td>\n",
       "      <td>negative</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>skin-ADL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ca006ONNL</th>\n",
       "      <td>6</td>\n",
       "      <td>F2</td>\n",
       "      <td>SA506</td>\n",
       "      <td>CGTGAGTG</td>\n",
       "      <td>SB702</td>\n",
       "      <td>CGAAGTAT</td>\n",
       "      <td>SB702SA506</td>\n",
       "      <td>CGAAGTAT-CGTGAGTG</td>\n",
       "      <td>1.010000e+21</td>\n",
       "      <td>F2</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>3/25/2015</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Unexposed</td>\n",
       "      <td>negative</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>skin-ADNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ca006ONNL2</th>\n",
       "      <td>6</td>\n",
       "      <td>H2</td>\n",
       "      <td>SA508</td>\n",
       "      <td>GACACCGT</td>\n",
       "      <td>SB702</td>\n",
       "      <td>CGAAGTAT</td>\n",
       "      <td>SB702SA508</td>\n",
       "      <td>CGAAGTAT-GACACCGT</td>\n",
       "      <td>1.010000e+21</td>\n",
       "      <td>H2</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>3/25/2015</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Unexposed</td>\n",
       "      <td>negative</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>skin-ADNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ca006ONPN</th>\n",
       "      <td>6</td>\n",
       "      <td>F3</td>\n",
       "      <td>SA506</td>\n",
       "      <td>CGTGAGTG</td>\n",
       "      <td>SB703</td>\n",
       "      <td>TAGCAGCT</td>\n",
       "      <td>SB703SA506</td>\n",
       "      <td>TAGCAGCT-CGTGAGTG</td>\n",
       "      <td>1.010000e+21</td>\n",
       "      <td>F3</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>3/25/2015</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Unexposed</td>\n",
       "      <td>negative</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>nares-AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ca006ONPN2</th>\n",
       "      <td>6</td>\n",
       "      <td>H3</td>\n",
       "      <td>SA508</td>\n",
       "      <td>GACACCGT</td>\n",
       "      <td>SB703</td>\n",
       "      <td>TAGCAGCT</td>\n",
       "      <td>SB703SA508</td>\n",
       "      <td>TAGCAGCT-GACACCGT</td>\n",
       "      <td>1.010000e+21</td>\n",
       "      <td>H3</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>3/25/2015</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Unexposed</td>\n",
       "      <td>negative</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>/Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...</td>\n",
       "      <td>nares-AD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PlateNumber PlateLocation     i5 i5Sequence     i7 i7Sequence  \\\n",
       "#sample-id                                                                  \n",
       "Ca009STL              1            A1  SA501   ATCGTACG  SA701   CGAGAGTT   \n",
       "900221                1            B1  SA502   ACTATCTG  SA701   CGAGAGTT   \n",
       "Ca010EBL              1            C1  SA503   TAGCGAGT  SA701   CGAGAGTT   \n",
       "900460                1            D1  SA504   CTGCGTGT  SA701   CGAGAGTT   \n",
       "900051                1            E1  SA505   TCATCGAG  SA701   CGAGAGTT   \n",
       "...                 ...           ...    ...        ...    ...        ...   \n",
       "Ca006ONL2             6            H1  SA508   GACACCGT  SB701   CTCGACTT   \n",
       "Ca006ONNL             6            F2  SA506   CGTGAGTG  SB702   CGAAGTAT   \n",
       "Ca006ONNL2            6            H2  SA508   GACACCGT  SB702   CGAAGTAT   \n",
       "Ca006ONPN             6            F3  SA506   CGTGAGTG  SB703   TAGCAGCT   \n",
       "Ca006ONPN2            6            H3  SA508   GACACCGT  SB703   TAGCAGCT   \n",
       "\n",
       "            identifier           Sequence      Plate ID Well location  ...  \\\n",
       "#sample-id                                                             ...   \n",
       "Ca009STL    SA701SA501  CGAGAGTT-ATCGTACG  1.010000e+21            A1  ...   \n",
       "900221      SA701SA502  CGAGAGTT-ACTATCTG  1.010000e+21            B1  ...   \n",
       "Ca010EBL    SA701SA503  CGAGAGTT-TAGCGAGT  1.010000e+21            C1  ...   \n",
       "900460      SA701SA504  CGAGAGTT-CTGCGTGT  1.010000e+21            D1  ...   \n",
       "900051      SA701SA505  CGAGAGTT-TCATCGAG  1.010000e+21            E1  ...   \n",
       "...                ...                ...           ...           ...  ...   \n",
       "Ca006ONL2   SB701SA508  CTCGACTT-GACACCGT  1.010000e+21            H1  ...   \n",
       "Ca006ONNL   SB702SA506  CGAAGTAT-CGTGAGTG  1.010000e+21            F2  ...   \n",
       "Ca006ONNL2  SB702SA508  CGAAGTAT-GACACCGT  1.010000e+21            H2  ...   \n",
       "Ca006ONPN   SB703SA506  TAGCAGCT-CGTGAGTG  1.010000e+21            F3  ...   \n",
       "Ca006ONPN2  SB703SA508  TAGCAGCT-GACACCGT  1.010000e+21            H3  ...   \n",
       "\n",
       "               sex enrolment_date enrolment_season hiv_exposure hiv_status  \\\n",
       "#sample-id                                                                   \n",
       "Ca009STL      male      4/16/2015          Autumn     Unexposed   negative   \n",
       "900221      female      8/11/2015           Winter    Unexposed   negative   \n",
       "Ca010EBL    female     11/20/2014           Spring    Unexposed   negative   \n",
       "900460      female      9/23/2015           Spring    Unexposed        NaN   \n",
       "900051        male      4/21/2015          Autumn     Unexposed   negative   \n",
       "...            ...            ...              ...          ...        ...   \n",
       "Ca006ONL2   female      3/25/2015           Autumn    Unexposed   negative   \n",
       "Ca006ONNL   female      3/25/2015           Autumn    Unexposed   negative   \n",
       "Ca006ONNL2  female      3/25/2015           Autumn    Unexposed   negative   \n",
       "Ca006ONPN   female      3/25/2015           Autumn    Unexposed   negative   \n",
       "Ca006ONPN2  female      3/25/2015           Autumn    Unexposed   negative   \n",
       "\n",
       "           household_size o_scorad  \\\n",
       "#sample-id                           \n",
       "Ca009STL              4.0       40   \n",
       "900221                7.0       34   \n",
       "Ca010EBL              7.0       21   \n",
       "900460                4.0       40   \n",
       "900051                7.0       41   \n",
       "...                   ...      ...   \n",
       "Ca006ONL2             3.0       34   \n",
       "Ca006ONNL             3.0       34   \n",
       "Ca006ONNL2            3.0       34   \n",
       "Ca006ONPN             3.0       34   \n",
       "Ca006ONPN2            3.0       34   \n",
       "\n",
       "                                                 FWD_filepath  \\\n",
       "#sample-id                                                      \n",
       "Ca009STL    /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   \n",
       "900221      /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   \n",
       "Ca010EBL    /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   \n",
       "900460      /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   \n",
       "900051      /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   \n",
       "...                                                       ...   \n",
       "Ca006ONL2   /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   \n",
       "Ca006ONNL   /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   \n",
       "Ca006ONNL2  /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   \n",
       "Ca006ONPN   /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   \n",
       "Ca006ONPN2  /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   \n",
       "\n",
       "                                                 REV_filepath      group  \n",
       "#sample-id                                                                \n",
       "Ca009STL    /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   skin-ADL  \n",
       "900221      /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   skin-ADL  \n",
       "Ca010EBL    /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   skin-ADL  \n",
       "900460      /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   skin-ADL  \n",
       "900051      /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   skin-ADL  \n",
       "...                                                       ...        ...  \n",
       "Ca006ONL2   /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   skin-ADL  \n",
       "Ca006ONNL   /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...  skin-ADNL  \n",
       "Ca006ONNL2  /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...  skin-ADNL  \n",
       "Ca006ONPN   /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   nares-AD  \n",
       "Ca006ONPN2  /Users/yac027/Gallo_lab/16S_AD_Dube_Dupont/ato...   nares-AD  \n",
       "\n",
       "[502 rows x 32 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the metadata\n",
    "metadata_path = '../Data/Metadata/updated_clean_ant_skin_metadata.tab'\n",
    "metadata = pd.read_csv(metadata_path, sep='\\t')\n",
    "# metadata['case_type'].value_counts()\n",
    "\n",
    "metadata['#sample-id'] = metadata['#sample-id'].str.replace('_', '')\n",
    "\n",
    "\n",
    "# Set Sample-ID as the index for the metadata dataframe \n",
    "metadata = metadata.set_index('#sample-id')\n",
    "\n",
    "\n",
    "# Create group column based on case_type to simplify group names\n",
    "metadata['group'] = metadata['case_type'].map({\n",
    "    'case-lesional skin': 'skin-ADL',\n",
    "    'case-nonlesional skin': 'skin-ADNL', \n",
    "    'control-nonlesional skin': 'skin-H',\n",
    "    'case-anterior nares': 'nares-AD',\n",
    "    'control-anterior nares': 'nares-H'\n",
    "})\n",
    "\n",
    "metadata\n",
    "# split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Pairwise Performance Comparison of Methods\n",
      "================================================================================\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "==================================================\n",
      "Top 10 important features for skin-ADL_vs_skin-H:\n",
      "==================================================\n",
      "\n",
      "V4:\n",
      "----------------------------------------\n",
      "                                                    mean_importance  \\\n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.022228   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.014513   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...         0.014384   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.011816   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.011095   \n",
      "GTGTCAGCAGCCGCGGTAATACGGAAGGTCCGGGCGTTATCCGGATT...         0.010805   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.010598   \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.010437   \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.009562   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAAGGTCCAGGCGTTATCCGGATT...         0.009415   \n",
      "\n",
      "                                                    std_importance  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.002204  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.001519  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...        0.006242  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.002399  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.002037  \n",
      "GTGTCAGCAGCCGCGGTAATACGGAAGGTCCGGGCGTTATCCGGATT...        0.003695  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.003182  \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.001076  \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.001293  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAAGGTCCAGGCGTTATCCGGATT...        0.003770  \n",
      "\n",
      "==================================================\n",
      "Top 10 important features for skin-ADNL_vs_skin-ADL:\n",
      "==================================================\n",
      "\n",
      "V4:\n",
      "----------------------------------------\n",
      "                                                    mean_importance  \\\n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.019623   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.014286   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.011899   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGGGCGAGCGTTGTCCGGAAT...         0.010970   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.010850   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTAATCGGAAT...         0.010834   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTAATCGGAAT...         0.010433   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.010197   \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.009532   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.009157   \n",
      "\n",
      "                                                    std_importance  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.003187  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.002673  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.001872  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGGGCGAGCGTTGTCCGGAAT...        0.000939  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.001263  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTAATCGGAAT...        0.001014  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTAATCGGAAT...        0.002014  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.002324  \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.001629  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.000919  \n",
      "\n",
      "==================================================\n",
      "Top 10 important features for skin-ADNL_vs_skin-H:\n",
      "==================================================\n",
      "\n",
      "V4:\n",
      "----------------------------------------\n",
      "                                                    mean_importance  \\\n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.018298   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.015288   \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.012710   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.012572   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGCGCAAGCGTTGTCCGGAAT...         0.011690   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.011445   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTATCCGGAAT...         0.010259   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.010244   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGAGCTAGCGTTGTTCGGAAT...         0.010070   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTGTCCGGAAT...         0.009031   \n",
      "\n",
      "                                                    std_importance  \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.001459  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.000154  \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.002332  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.001885  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGCGCAAGCGTTGTCCGGAAT...        0.003786  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.004891  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTATCCGGAAT...        0.002361  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.000887  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGAGCTAGCGTTGTTCGGAAT...        0.002571  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTGTCCGGAAT...        0.000782  \n",
      "\n",
      "==================================================\n",
      "Top 10 important features for nares-AD_vs_nares-H:\n",
      "==================================================\n",
      "\n",
      "V4:\n",
      "----------------------------------------\n",
      "                                                    mean_importance  \\\n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.027070   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.022989   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAAT...         0.021538   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGACAAGCGTTGTCCGGATT...         0.021311   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.019339   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...         0.017363   \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.017226   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.015726   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.012700   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.012563   \n",
      "\n",
      "                                                    std_importance  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.006143  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.000278  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAAT...        0.002732  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGACAAGCGTTGTCCGGATT...        0.001228  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.007307  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...        0.002012  \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.002276  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.000797  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.000467  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.001777  \n"
     ]
    }
   ],
   "source": [
    "# Set overall styling for plots\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "# Custom function for group-stratified k-fold\n",
    "def group_stratified_kfold(X, y, groups, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Custom implementation of cross-validation that respects both groups and stratification\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Feature matrix\n",
    "    y : Series\n",
    "        Target labels\n",
    "    groups : Series\n",
    "        Group labels for samples (e.g., pid)\n",
    "    n_splits : int\n",
    "        Number of folds\n",
    "    random_state : int\n",
    "        Random seed\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples\n",
    "        Each tuple contains (train_indices, test_indices)\n",
    "    \"\"\"\n",
    "    # Get unique groups\n",
    "    unique_groups = np.unique(groups)\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(unique_groups)\n",
    "    \n",
    "    # Create label distribution per group\n",
    "    group_label_dist = {}\n",
    "    for group in unique_groups:\n",
    "        group_mask = groups == group\n",
    "        group_y = y[group_mask]\n",
    "        group_label_dist[group] = {label: np.sum(group_y == label) for label in np.unique(y)}\n",
    "    \n",
    "    # Initialize folds with empty lists\n",
    "    folds = [[] for _ in range(n_splits)]\n",
    "    \n",
    "    # Track current distribution of labels in each fold\n",
    "    fold_label_dist = [{label: 0 for label in np.unique(y)} for _ in range(n_splits)]\n",
    "    \n",
    "    # Sort groups by size (number of samples) in descending order to place larger groups first\n",
    "    sorted_groups = sorted(unique_groups, key=lambda g: sum(groups == g), reverse=True)\n",
    "    \n",
    "    # Assign groups to folds\n",
    "    for group in sorted_groups:\n",
    "        # Calculate which fold would benefit most from this group\n",
    "        # by minimizing the imbalance across all labels\n",
    "        best_fold = 0\n",
    "        min_imbalance = float('inf')\n",
    "        \n",
    "        group_size = sum(groups == group)\n",
    "        \n",
    "        for fold_idx in range(n_splits):\n",
    "            # Calculate current imbalance if we add this group\n",
    "            temp_fold_dist = fold_label_dist[fold_idx].copy()\n",
    "            for label, count in group_label_dist[group].items():\n",
    "                temp_fold_dist[label] += count\n",
    "            \n",
    "            # Calculate imbalance as variance of label proportions\n",
    "            fold_size = sum(temp_fold_dist.values())\n",
    "            if fold_size == 0:\n",
    "                proportions = [0] * len(temp_fold_dist)\n",
    "            else:\n",
    "                proportions = [count / fold_size for count in temp_fold_dist.values()]\n",
    "            \n",
    "            imbalance = np.var(proportions) + fold_size / (sum(groups.shape) / n_splits)\n",
    "            \n",
    "            if imbalance < min_imbalance:\n",
    "                min_imbalance = imbalance\n",
    "                best_fold = fold_idx\n",
    "        \n",
    "        # Assign group to best fold\n",
    "        folds[best_fold].extend(np.where(groups == group)[0])\n",
    "        # Update fold distribution\n",
    "        for label, count in group_label_dist[group].items():\n",
    "            fold_label_dist[best_fold][label] += count\n",
    "    \n",
    "    # Create train/test indices\n",
    "    train_test_indices = []\n",
    "    for i in range(n_splits):\n",
    "        test_idx = np.array(folds[i])\n",
    "        train_idx = np.concatenate([folds[j] for j in range(n_splits) if j != i])\n",
    "        train_test_indices.append((train_idx, test_idx))\n",
    "    \n",
    "    return train_test_indices\n",
    "\n",
    "# Modified function to run group-stratified cross-validation with feature importance\n",
    "def run_group_stratified_cv(X, y, groups, n_splits=5):\n",
    "    # Get group-stratified folds\n",
    "    folds = group_stratified_kfold(X, y, groups, n_splits=n_splits)\n",
    "    \n",
    "    # Initialize arrays to store results\n",
    "    cv_results = []\n",
    "    feature_importances = pd.DataFrame(index=X.columns)\n",
    "    fold_aucs = []\n",
    "    \n",
    "    # Run cross-validation\n",
    "    for i, (train_idx, test_idx) in enumerate(folds):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # Handle cases where train set might contain only one class\n",
    "        if len(np.unique(y_train)) < 2 or len(np.unique(y_test)) < 2:\n",
    "            print(f\"Skipping fold {i+1} due to insufficient class representation\")\n",
    "            continue\n",
    "            \n",
    "        # Train classifier\n",
    "        clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        probas = clf.predict_proba(X_test)\n",
    "        \n",
    "        # Store feature importance for this fold\n",
    "        feature_importances[f'fold_{i}'] = clf.feature_importances_\n",
    "        \n",
    "        # Store results\n",
    "        fpr, tpr, _ = roc_curve(y_test, probas[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        fold_aucs.append(roc_auc)\n",
    "        \n",
    "        cv_results.append({\n",
    "            'y_true': y_test,\n",
    "            'y_proba': probas[:, 1],\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr,\n",
    "            'auc': roc_auc,\n",
    "            'fold': i\n",
    "        })\n",
    "    \n",
    "    # Calculate mean feature importance across folds\n",
    "    feature_importances['mean_importance'] = feature_importances.mean(axis=1)\n",
    "    feature_importances['std_importance'] = feature_importances.std(axis=1)\n",
    "    feature_importances = feature_importances.sort_values('mean_importance', ascending=False)\n",
    "    \n",
    "    return cv_results, feature_importances, fold_aucs\n",
    "\n",
    "# Function to compute and plot ROC curves with error bars plus perform pairwise comparisons\n",
    "def plot_roc_curves_with_comparisons(tables_dict, metadata, pair_comparisons, n_splits=5):\n",
    "    # Separate comparisons\n",
    "    skin_comparisons = [(\"skin-ADL\", \"skin-H\"), (\"skin-ADNL\", \"skin-ADL\"), (\"skin-ADNL\", \"skin-H\")]\n",
    "    nares_comparisons = [(\"nares-AD\", \"nares-H\")]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "    color_map_skin = {\n",
    "        'skin-ADL_vs_skin-H': 'blue',\n",
    "        'skin-ADNL_vs_skin-ADL': 'green',\n",
    "        'skin-ADNL_vs_skin-H': 'purple'\n",
    "    }\n",
    "    color_map_nares = {\n",
    "        'nares-AD_vs_nares-H': 'orange'\n",
    "    }\n",
    "\n",
    "    all_feature_importances = {}\n",
    "    all_fold_aucs = {}\n",
    "\n",
    "    for label1, label2 in pair_comparisons:\n",
    "        comparison_key = f'{label1}_vs_{label2}'\n",
    "        is_skin = (label1.startswith(\"skin\") and label2.startswith(\"skin\"))\n",
    "        ax = axs[0] if is_skin else axs[1]\n",
    "\n",
    "        ax.set_title(\"Skin Comparisons\" if is_skin else \"Nares Comparison\", fontsize=16)\n",
    "        all_feature_importances[comparison_key] = {}\n",
    "        all_fold_aucs[comparison_key] = {}\n",
    "\n",
    "        for table_name, table in tables_dict.items():\n",
    "            meta_subset = metadata[metadata['group'].isin([label1, label2])]\n",
    "            common_samples = table.index.intersection(meta_subset.index)\n",
    "            X = table.loc[common_samples]\n",
    "            meta_filtered = meta_subset.loc[common_samples]\n",
    "\n",
    "            if len(common_samples) < 10:\n",
    "                print(f\"Skipping {table_name} for {label1} vs {label2}: insufficient samples ({len(common_samples)})\")\n",
    "                continue\n",
    "\n",
    "            y = meta_filtered['group'].map({label1: 0, label2: 1})\n",
    "            groups = meta_filtered['pid']\n",
    "            cv_results, feature_imp, fold_aucs = run_group_stratified_cv(X, y, groups, n_splits=n_splits)\n",
    "            all_feature_importances[comparison_key][table_name] = feature_imp\n",
    "            all_fold_aucs[comparison_key][table_name] = fold_aucs\n",
    "\n",
    "            if len(cv_results) < 2:\n",
    "                print(f\"Skipping {table_name} for {label1} vs {label2}: CV returned insufficient results\")\n",
    "                continue\n",
    "\n",
    "            mean_fpr = np.linspace(0, 1, 100)\n",
    "            tprs, aucs = [], []\n",
    "            for result in cv_results:\n",
    "                tprs.append(interp(mean_fpr, result['fpr'], result['tpr']))\n",
    "                tprs[-1][0] = 0.0\n",
    "                aucs.append(result['auc'])\n",
    "\n",
    "            mean_tpr = np.mean(tprs, axis=0)\n",
    "            mean_tpr[-1] = 1.0\n",
    "            std_tpr = np.std(tprs, axis=0)\n",
    "            tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "            tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "            # Color based on type\n",
    "            plot_color = color_map_skin.get(comparison_key) if is_skin else color_map_nares.get(comparison_key)\n",
    "\n",
    "            ax.plot(mean_fpr, mean_tpr, lw=2,\n",
    "                    label=f'{label1} vs {label2} (AUC = {np.mean(aucs):.2f} ± {np.std(aucs):.2f})',\n",
    "                    color=plot_color)\n",
    "            ax.fill_between(mean_fpr, tprs_lower, tprs_upper, alpha=0.3, color=plot_color)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "        ax.set_xlabel('False Positive Rate', fontsize=14)\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "        ax.legend(loc='lower right', fontsize=10)\n",
    "\n",
    "    axs[0].set_ylabel('True Positive Rate', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    pairwise_comparisons = compute_pairwise_comparisons(all_fold_aucs)\n",
    "    return fig, all_feature_importances, pairwise_comparisons\n",
    "\n",
    "\n",
    "\n",
    "# Function to perform pairwise statistical tests\n",
    "def compute_pairwise_comparisons(fold_aucs_dict):\n",
    "    \"\"\"\n",
    "    Perform pairwise statistical tests between methods for each task\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fold_aucs_dict : dict\n",
    "        Dictionary with fold-wise AUC values for each method\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Table with pairwise comparisons and p-values\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for task, methods_dict in fold_aucs_dict.items():\n",
    "        # Get list of methods that have AUC values\n",
    "        methods = list(methods_dict.keys())\n",
    "        \n",
    "        # Perform pairwise comparisons\n",
    "        for method1, method2 in combinations(methods, 2):\n",
    "            # Get AUC values for both methods\n",
    "            aucs1 = methods_dict[method1]\n",
    "            aucs2 = methods_dict[method2]\n",
    "            \n",
    "            # Ensure equal length (use only common folds)\n",
    "            min_len = min(len(aucs1), len(aucs2))\n",
    "            if min_len < 2:\n",
    "                continue\n",
    "                \n",
    "            aucs1 = aucs1[:min_len]\n",
    "            aucs2 = aucs2[:min_len]\n",
    "            \n",
    "            # Calculate mean AUCs\n",
    "            mean_auc1 = np.mean(aucs1)\n",
    "            mean_auc2 = np.mean(aucs2)\n",
    "            diff_auc = mean_auc1 - mean_auc2\n",
    "            \n",
    "            # Perform statistical tests\n",
    "            # Wilcoxon signed-rank test (non-parametric)\n",
    "            try:\n",
    "                _, p_wilcoxon = wilcoxon(aucs1, aucs2)\n",
    "            except:\n",
    "                p_wilcoxon = np.nan\n",
    "                \n",
    "            # Paired t-test (parametric)\n",
    "            _, p_ttest = ttest_rel(aucs1, aucs2)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'Task': task,\n",
    "                'Method 1': method1,\n",
    "                'Method 2': method2,\n",
    "                'Mean AUC 1': mean_auc1,\n",
    "                'Mean AUC 2': mean_auc2,\n",
    "                'AUC Difference': diff_auc,\n",
    "                'p-value (Wilcoxon)': p_wilcoxon,\n",
    "                'p-value (t-test)': p_ttest,\n",
    "                'Significant (p<0.05)': (p_wilcoxon < 0.05) if not np.isnan(p_wilcoxon) else (p_ttest < 0.05)\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Create a dictionary of tables\n",
    "tables = {\n",
    "    'V4': df\n",
    "}\n",
    "\n",
    "# Define pairwise comparisons\n",
    "comparisons = [('skin-ADL', 'skin-H'), ('skin-ADNL', 'skin-ADL'), ('skin-ADNL', 'skin-H'), ('nares-AD', 'nares-H')]\n",
    "\n",
    "\n",
    "# Set number of CV splits\n",
    "n_cv_splits = 3\n",
    "\n",
    "# Run analysis and plot\n",
    "fig, feature_importances, pairwise_stats = plot_roc_curves_with_comparisons(tables, metadata, comparisons, n_splits=n_cv_splits)\n",
    "\n",
    "# Display pairwise performance comparison table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Pairwise Performance Comparison of Methods\")\n",
    "print(\"=\"*80)\n",
    "print(pairwise_stats.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# Display the top 10 most important features for each comparison and data type\n",
    "for comparison, data_types in feature_importances.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Top 10 important features for {comparison}:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    for data_type, features_df in data_types.items():\n",
    "        print(f\"\\n{data_type}:\")\n",
    "        print(\"-\" * 40)\n",
    "        top_features = features_df.sort_values('mean_importance', ascending=False).head(10)\n",
    "        print(top_features[['mean_importance', 'std_importance']])\n",
    "\n",
    "# Add supertitle to the plot\n",
    "plt.suptitle('Random Forest Classifications by 16S V4 ASVs', fontsize=18, y=1.02)\n",
    "\n",
    "plt.savefig('../Plots/Analysis_figures/Random_Forest/rf_ASV_skin-groups_nares-groups.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "microbiome_type\n",
       "skin     305\n",
       "nares    197\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add microbiome_type column based on group values\n",
    "metadata['microbiome_type'] = metadata['group'].apply(lambda x: 'skin' if x.startswith('skin') else 'nares' if x.startswith('nares') else None)\n",
    "metadata['microbiome_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Pairwise Performance Comparison of Methods\n",
      "================================================================================\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "==================================================\n",
      "Top 10 important features for skin_vs_nares:\n",
      "==================================================\n",
      "\n",
      "V4:\n",
      "----------------------------------------\n",
      "                                                    mean_importance  \\\n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGACAAGCGTTGTCCGGATT...         0.055981   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAAT...         0.050087   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.033611   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.030663   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...         0.023109   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTATCCGGAAT...         0.022101   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.020351   \n",
      "GTGCCAGCAGCCGCGGTAATACAGAGGGTGCGAGCGTTAATCGGAAT...         0.019715   \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.018544   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCAAGCGTTAATCGGAAT...         0.018052   \n",
      "\n",
      "                                                    std_importance  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGACAAGCGTTGTCCGGATT...        0.004162  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAAT...        0.006663  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.001890  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.005104  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...        0.003803  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTATCCGGAAT...        0.000728  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.000638  \n",
      "GTGCCAGCAGCCGCGGTAATACAGAGGGTGCGAGCGTTAATCGGAAT...        0.000627  \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.001530  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCAAGCGTTAATCGGAAT...        0.003618  \n"
     ]
    }
   ],
   "source": [
    "# Set overall styling for plots\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "# Custom function for group-stratified k-fold\n",
    "def group_stratified_kfold(X, y, groups, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Custom implementation of cross-validation that respects both groups and stratification\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Feature matrix\n",
    "    y : Series\n",
    "        Target labels\n",
    "    groups : Series\n",
    "        Group labels for samples (e.g., pid)\n",
    "    n_splits : int\n",
    "        Number of folds\n",
    "    random_state : int\n",
    "        Random seed\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples\n",
    "        Each tuple contains (train_indices, test_indices)\n",
    "    \"\"\"\n",
    "    # Get unique groups\n",
    "    unique_groups = np.unique(groups)\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(unique_groups)\n",
    "    \n",
    "    # Create label distribution per group\n",
    "    group_label_dist = {}\n",
    "    for group in unique_groups:\n",
    "        group_mask = groups == group\n",
    "        group_y = y[group_mask]\n",
    "        group_label_dist[group] = {label: np.sum(group_y == label) for label in np.unique(y)}\n",
    "    \n",
    "    # Initialize folds with empty lists\n",
    "    folds = [[] for _ in range(n_splits)]\n",
    "    \n",
    "    # Track current distribution of labels in each fold\n",
    "    fold_label_dist = [{label: 0 for label in np.unique(y)} for _ in range(n_splits)]\n",
    "    \n",
    "    # Sort groups by size (number of samples) in descending order to place larger groups first\n",
    "    sorted_groups = sorted(unique_groups, key=lambda g: sum(groups == g), reverse=True)\n",
    "    \n",
    "    # Assign groups to folds\n",
    "    for group in sorted_groups:\n",
    "        # Calculate which fold would benefit most from this group\n",
    "        # by minimizing the imbalance across all labels\n",
    "        best_fold = 0\n",
    "        min_imbalance = float('inf')\n",
    "        \n",
    "        group_size = sum(groups == group)\n",
    "        \n",
    "        for fold_idx in range(n_splits):\n",
    "            # Calculate current imbalance if we add this group\n",
    "            temp_fold_dist = fold_label_dist[fold_idx].copy()\n",
    "            for label, count in group_label_dist[group].items():\n",
    "                temp_fold_dist[label] += count\n",
    "            \n",
    "            # Calculate imbalance as variance of label proportions\n",
    "            fold_size = sum(temp_fold_dist.values())\n",
    "            if fold_size == 0:\n",
    "                proportions = [0] * len(temp_fold_dist)\n",
    "            else:\n",
    "                proportions = [count / fold_size for count in temp_fold_dist.values()]\n",
    "            \n",
    "            imbalance = np.var(proportions) + fold_size / (sum(groups.shape) / n_splits)\n",
    "            \n",
    "            if imbalance < min_imbalance:\n",
    "                min_imbalance = imbalance\n",
    "                best_fold = fold_idx\n",
    "        \n",
    "        # Assign group to best fold\n",
    "        folds[best_fold].extend(np.where(groups == group)[0])\n",
    "        # Update fold distribution\n",
    "        for label, count in group_label_dist[group].items():\n",
    "            fold_label_dist[best_fold][label] += count\n",
    "    \n",
    "    # Create train/test indices\n",
    "    train_test_indices = []\n",
    "    for i in range(n_splits):\n",
    "        test_idx = np.array(folds[i])\n",
    "        train_idx = np.concatenate([folds[j] for j in range(n_splits) if j != i])\n",
    "        train_test_indices.append((train_idx, test_idx))\n",
    "    \n",
    "    return train_test_indices\n",
    "\n",
    "# Modified function to run group-stratified cross-validation with feature importance\n",
    "def run_group_stratified_cv(X, y, groups, n_splits=5):\n",
    "    # Get group-stratified folds\n",
    "    folds = group_stratified_kfold(X, y, groups, n_splits=n_splits)\n",
    "    \n",
    "    # Initialize arrays to store results\n",
    "    cv_results = []\n",
    "    feature_importances = pd.DataFrame(index=X.columns)\n",
    "    fold_aucs = []\n",
    "    \n",
    "    # Run cross-validation\n",
    "    for i, (train_idx, test_idx) in enumerate(folds):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # Handle cases where train set might contain only one class\n",
    "        if len(np.unique(y_train)) < 2 or len(np.unique(y_test)) < 2:\n",
    "            print(f\"Skipping fold {i+1} due to insufficient class representation\")\n",
    "            continue\n",
    "            \n",
    "        # Train classifier\n",
    "        clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        probas = clf.predict_proba(X_test)\n",
    "        \n",
    "        # Store feature importance for this fold\n",
    "        feature_importances[f'fold_{i}'] = clf.feature_importances_\n",
    "        \n",
    "        # Store results\n",
    "        fpr, tpr, _ = roc_curve(y_test, probas[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        fold_aucs.append(roc_auc)\n",
    "        \n",
    "        cv_results.append({\n",
    "            'y_true': y_test,\n",
    "            'y_proba': probas[:, 1],\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr,\n",
    "            'auc': roc_auc,\n",
    "            'fold': i\n",
    "        })\n",
    "    \n",
    "    # Calculate mean feature importance across folds\n",
    "    feature_importances['mean_importance'] = feature_importances.mean(axis=1)\n",
    "    feature_importances['std_importance'] = feature_importances.std(axis=1)\n",
    "    feature_importances = feature_importances.sort_values('mean_importance', ascending=False)\n",
    "    \n",
    "    return cv_results, feature_importances, fold_aucs\n",
    "\n",
    "# Function to compute and plot ROC curves with error bars plus perform pairwise comparisons\n",
    "def plot_roc_curves_with_comparisons(tables_dict, metadata, pair_comparisons, n_splits=5):\n",
    "    # Separate comparisons\n",
    "    comparisons = [(\"skin\", \"nares\")]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(6, 6), sharey=True)\n",
    "\n",
    "    color_map = {\n",
    "        'skin_vs_nares': 'black',\n",
    "        'skin-ADNL_vs_skin-H': 'purple'\n",
    "    }\n",
    "\n",
    "\n",
    "    all_feature_importances = {}\n",
    "    all_fold_aucs = {}\n",
    "\n",
    "    for label1, label2 in pair_comparisons:\n",
    "        comparison_key = f'{label1}_vs_{label2}'\n",
    "        is_skin = (label1.startswith(\"skin\") and label2.startswith(\"skin\"))\n",
    "        ax = axs[0] if is_skin else axs[1]\n",
    "\n",
    "        ax.set_title(\"Skin Comparisons\" if is_skin else \"Nares Comparison\", fontsize=16)\n",
    "        all_feature_importances[comparison_key] = {}\n",
    "        all_fold_aucs[comparison_key] = {}\n",
    "\n",
    "        for table_name, table in tables_dict.items():\n",
    "            meta_subset = metadata[metadata['microbiome_type'].isin([label1, label2])]\n",
    "            common_samples = table.index.intersection(meta_subset.index)\n",
    "            X = table.loc[common_samples]\n",
    "            meta_filtered = meta_subset.loc[common_samples]\n",
    "\n",
    "            if len(common_samples) < 10:\n",
    "                print(f\"Skipping {table_name} for {label1} vs {label2}: insufficient samples ({len(common_samples)})\")\n",
    "                continue\n",
    "\n",
    "            y = meta_filtered['microbiome_type'].map({label1: 0, label2: 1})\n",
    "            groups = meta_filtered['pid']\n",
    "            cv_results, feature_imp, fold_aucs = run_group_stratified_cv(X, y, groups, n_splits=n_splits)\n",
    "            all_feature_importances[comparison_key][table_name] = feature_imp\n",
    "            all_fold_aucs[comparison_key][table_name] = fold_aucs\n",
    "\n",
    "            if len(cv_results) < 2:\n",
    "                print(f\"Skipping {table_name} for {label1} vs {label2}: CV returned insufficient results\")\n",
    "                continue\n",
    "\n",
    "            mean_fpr = np.linspace(0, 1, 100)\n",
    "            tprs, aucs = [], []\n",
    "            for result in cv_results:\n",
    "                tprs.append(interp(mean_fpr, result['fpr'], result['tpr']))\n",
    "                tprs[-1][0] = 0.0\n",
    "                aucs.append(result['auc'])\n",
    "\n",
    "            mean_tpr = np.mean(tprs, axis=0)\n",
    "            mean_tpr[-1] = 1.0\n",
    "            std_tpr = np.std(tprs, axis=0)\n",
    "            tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "            tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "            # Color based on type\n",
    "            plot_color = color_map.get(comparison_key) if is_skin else color_map.get(comparison_key)\n",
    "\n",
    "            ax.plot(mean_fpr, mean_tpr, lw=2,\n",
    "                    label=f'{label1} vs {label2} (AUC = {np.mean(aucs):.2f} ± {np.std(aucs):.2f})',\n",
    "                    color=plot_color)\n",
    "            ax.fill_between(mean_fpr, tprs_lower, tprs_upper, alpha=0.3, color=plot_color)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "        ax.set_xlabel('False Positive Rate', fontsize=14)\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "        ax.legend(loc='lower right', fontsize=10)\n",
    "\n",
    "    axs[0].set_ylabel('True Positive Rate', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    pairwise_comparisons = compute_pairwise_comparisons(all_fold_aucs)\n",
    "    return fig, all_feature_importances, pairwise_comparisons\n",
    "\n",
    "\n",
    "\n",
    "# Function to perform pairwise statistical tests\n",
    "def compute_pairwise_comparisons(fold_aucs_dict):\n",
    "    \"\"\"\n",
    "    Perform pairwise statistical tests between methods for each task\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fold_aucs_dict : dict\n",
    "        Dictionary with fold-wise AUC values for each method\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Table with pairwise comparisons and p-values\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for task, methods_dict in fold_aucs_dict.items():\n",
    "        # Get list of methods that have AUC values\n",
    "        methods = list(methods_dict.keys())\n",
    "        \n",
    "        # Perform pairwise comparisons\n",
    "        for method1, method2 in combinations(methods, 2):\n",
    "            # Get AUC values for both methods\n",
    "            aucs1 = methods_dict[method1]\n",
    "            aucs2 = methods_dict[method2]\n",
    "            \n",
    "            # Ensure equal length (use only common folds)\n",
    "            min_len = min(len(aucs1), len(aucs2))\n",
    "            if min_len < 2:\n",
    "                continue\n",
    "                \n",
    "            aucs1 = aucs1[:min_len]\n",
    "            aucs2 = aucs2[:min_len]\n",
    "            \n",
    "            # Calculate mean AUCs\n",
    "            mean_auc1 = np.mean(aucs1)\n",
    "            mean_auc2 = np.mean(aucs2)\n",
    "            diff_auc = mean_auc1 - mean_auc2\n",
    "            \n",
    "            # Perform statistical tests\n",
    "            # Wilcoxon signed-rank test (non-parametric)\n",
    "            try:\n",
    "                _, p_wilcoxon = wilcoxon(aucs1, aucs2)\n",
    "            except:\n",
    "                p_wilcoxon = np.nan\n",
    "                \n",
    "            # Paired t-test (parametric)\n",
    "            _, p_ttest = ttest_rel(aucs1, aucs2)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'Task': task,\n",
    "                'Method 1': method1,\n",
    "                'Method 2': method2,\n",
    "                'Mean AUC 1': mean_auc1,\n",
    "                'Mean AUC 2': mean_auc2,\n",
    "                'AUC Difference': diff_auc,\n",
    "                'p-value (Wilcoxon)': p_wilcoxon,\n",
    "                'p-value (t-test)': p_ttest,\n",
    "                'Significant (p<0.05)': (p_wilcoxon < 0.05) if not np.isnan(p_wilcoxon) else (p_ttest < 0.05)\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Create a dictionary of tables\n",
    "tables = {\n",
    "    'V4': df\n",
    "}\n",
    "\n",
    "# Define pairwise comparisons\n",
    "comparisons = [('skin', 'nares')]\n",
    "\n",
    "\n",
    "# Set number of CV splits\n",
    "n_cv_splits = 3\n",
    "\n",
    "# Run analysis and plot\n",
    "fig, feature_importances, pairwise_stats = plot_roc_curves_with_comparisons(tables, metadata, comparisons, n_splits=n_cv_splits)\n",
    "\n",
    "# Display pairwise performance comparison table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Pairwise Performance Comparison of Methods\")\n",
    "print(\"=\"*80)\n",
    "print(pairwise_stats.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# Display the top 10 most important features for each comparison and data type\n",
    "for comparison, data_types in feature_importances.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Top 10 important features for {comparison}:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    for data_type, features_df in data_types.items():\n",
    "        print(f\"\\n{data_type}:\")\n",
    "        print(\"-\" * 40)\n",
    "        top_features = features_df.sort_values('mean_importance', ascending=False).head(10)\n",
    "        print(top_features[['mean_importance', 'std_importance']])\n",
    "\n",
    "# Add supertitle to the plot\n",
    "plt.suptitle('Random Forest Classifications by 16S V4 ASVs', fontsize=18, y=1.02)\n",
    "\n",
    "plt.savefig('../Plots/Analysis_figures/Random_Forest/rf_ASV_skin_vs_nares.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 ASVs for comparison: skin_vs_nares\n",
      "============================================================\n",
      "\n",
      "V4 dataset:\n",
      "                                                    mean_importance  \\\n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGACAAGCGTTGTCCGGATT...         0.055981   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAAT...         0.050087   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.033611   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.030663   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...         0.023109   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTATCCGGAAT...         0.022101   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.020351   \n",
      "GTGCCAGCAGCCGCGGTAATACAGAGGGTGCGAGCGTTAATCGGAAT...         0.019715   \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.018544   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCAAGCGTTAATCGGAAT...         0.018052   \n",
      "\n",
      "                                                    std_importance  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGACAAGCGTTGTCCGGATT...        0.004162  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAAT...        0.006663  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.001890  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.005104  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...        0.003803  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTATCCGGAAT...        0.000728  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.000638  \n",
      "GTGCCAGCAGCCGCGGTAATACAGAGGGTGCGAGCGTTAATCGGAAT...        0.000627  \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.001530  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCAAGCGTTAATCGGAAT...        0.003618  \n"
     ]
    }
   ],
   "source": [
    "# Save or print the top 10 ASVs per comparison\n",
    "top_asv_summary = []\n",
    "\n",
    "for comparison_key, method_dict in feature_importances.items():\n",
    "    print(f\"\\nTop 10 ASVs for comparison: {comparison_key}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for method_name, imp_df in method_dict.items():\n",
    "        top_asvs = imp_df.sort_values('mean_importance', ascending=False).head(10)\n",
    "        print(f\"\\n{method_name} dataset:\")\n",
    "        print(top_asvs[['mean_importance', 'std_importance']])\n",
    "\n",
    "        # Optional: store in a summary list for later export\n",
    "        for feature_name, row in top_asvs.iterrows():\n",
    "            top_asv_summary.append({\n",
    "                'Comparison': comparison_key,\n",
    "                'Method': method_name,\n",
    "                'ASV': feature_name,\n",
    "                'Mean Importance': row['mean_importance'],\n",
    "                'Std Importance': row['std_importance']\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame for CSV or further use\n",
    "top_asv_df = pd.DataFrame(top_asv_summary)\n",
    "\n",
    "# Save to CSV\n",
    "top_asv_df.to_csv('../Plots/Analysis_figures/Random_Forest/top10_ASVs_per_comparison.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Pairwise Performance Comparison of Methods\n",
      "================================================================================\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "==================================================\n",
      "Top 10 important features for skin-ADL_vs_skin-H:\n",
      "==================================================\n",
      "\n",
      "V4:\n",
      "----------------------------------------\n",
      "                                                    mean_importance  \\\n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.022228   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.014513   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...         0.014384   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.011816   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.011095   \n",
      "GTGTCAGCAGCCGCGGTAATACGGAAGGTCCGGGCGTTATCCGGATT...         0.010805   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.010598   \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.010437   \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.009562   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAAGGTCCAGGCGTTATCCGGATT...         0.009415   \n",
      "\n",
      "                                                    std_importance  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.002204  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.001519  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...        0.006242  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.002399  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.002037  \n",
      "GTGTCAGCAGCCGCGGTAATACGGAAGGTCCGGGCGTTATCCGGATT...        0.003695  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.003182  \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.001076  \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.001293  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAAGGTCCAGGCGTTATCCGGATT...        0.003770  \n",
      "\n",
      "==================================================\n",
      "Top 10 important features for skin-ADNL_vs_skin-ADL:\n",
      "==================================================\n",
      "\n",
      "V4:\n",
      "----------------------------------------\n",
      "                                                    mean_importance  \\\n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.019623   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.014286   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.011899   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGGGCGAGCGTTGTCCGGAAT...         0.010970   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.010850   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTAATCGGAAT...         0.010834   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTAATCGGAAT...         0.010433   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.010197   \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.009532   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.009157   \n",
      "\n",
      "                                                    std_importance  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.003187  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.002673  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.001872  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGGGCGAGCGTTGTCCGGAAT...        0.000939  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.001263  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTAATCGGAAT...        0.001014  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTAATCGGAAT...        0.002014  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.002324  \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.001629  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.000919  \n",
      "\n",
      "==================================================\n",
      "Top 10 important features for skin-ADNL_vs_skin-H:\n",
      "==================================================\n",
      "\n",
      "V4:\n",
      "----------------------------------------\n",
      "                                                    mean_importance  \\\n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.018298   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.015288   \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.012710   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.012572   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGCGCAAGCGTTGTCCGGAAT...         0.011690   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.011445   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTATCCGGAAT...         0.010259   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.010244   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGAGCTAGCGTTGTTCGGAAT...         0.010070   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTGTCCGGAAT...         0.009031   \n",
      "\n",
      "                                                    std_importance  \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.001459  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.000154  \n",
      "GTGCCAGCCGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.002332  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.001885  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGCGCAAGCGTTGTCCGGAAT...        0.003786  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.004891  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTATCCGGAAT...        0.002361  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.000887  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGAGCTAGCGTTGTTCGGAAT...        0.002571  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTGTCCGGAAT...        0.000782  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "from itertools import combinations\n",
    "from scipy import interp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "def group_stratified_kfold(X, y, groups, n_splits=5, random_state=42):\n",
    "    unique_groups = np.unique(groups)\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(unique_groups)\n",
    "\n",
    "    group_label_dist = {}\n",
    "    for group in unique_groups:\n",
    "        group_mask = groups == group\n",
    "        group_y = y[group_mask]\n",
    "        group_label_dist[group] = {label: np.sum(group_y == label) for label in np.unique(y)}\n",
    "\n",
    "    folds = [[] for _ in range(n_splits)]\n",
    "    fold_label_dist = [{label: 0 for label in np.unique(y)} for _ in range(n_splits)]\n",
    "    sorted_groups = sorted(unique_groups, key=lambda g: sum(groups == g), reverse=True)\n",
    "\n",
    "    for group in sorted_groups:\n",
    "        best_fold, min_imbalance = 0, float('inf')\n",
    "        for fold_idx in range(n_splits):\n",
    "            temp_fold_dist = fold_label_dist[fold_idx].copy()\n",
    "            for label, count in group_label_dist[group].items():\n",
    "                temp_fold_dist[label] += count\n",
    "            fold_size = sum(temp_fold_dist.values())\n",
    "            proportions = [count / fold_size if fold_size else 0 for count in temp_fold_dist.values()]\n",
    "            imbalance = np.var(proportions) + fold_size / (len(groups) / n_splits)\n",
    "            if imbalance < min_imbalance:\n",
    "                min_imbalance = imbalance\n",
    "                best_fold = fold_idx\n",
    "        folds[best_fold].extend(np.where(groups == group)[0])\n",
    "        for label, count in group_label_dist[group].items():\n",
    "            fold_label_dist[best_fold][label] += count\n",
    "\n",
    "    train_test_indices = []\n",
    "    for i in range(n_splits):\n",
    "        test_idx = np.array(folds[i])\n",
    "        train_idx = np.concatenate([folds[j] for j in range(n_splits) if j != i])\n",
    "        train_test_indices.append((train_idx, test_idx))\n",
    "\n",
    "    return train_test_indices\n",
    "\n",
    "def run_group_stratified_cv(X, y, groups, n_splits=5):\n",
    "    folds = group_stratified_kfold(X, y, groups, n_splits=n_splits)\n",
    "    cv_results = []\n",
    "    feature_importances = pd.DataFrame(index=X.columns)\n",
    "    fold_aucs = []\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(folds):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        if len(np.unique(y_train)) < 2 or len(np.unique(y_test)) < 2:\n",
    "            print(f\"Skipping fold {i+1} due to insufficient class representation\")\n",
    "            continue\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        probas = clf.predict_proba(X_test)\n",
    "        feature_importances[f'fold_{i}'] = clf.feature_importances_\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, probas[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        fold_aucs.append(roc_auc)\n",
    "\n",
    "        cv_results.append({\n",
    "            'y_true': y_test,\n",
    "            'y_proba': probas[:, 1],\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr,\n",
    "            'auc': roc_auc,\n",
    "            'fold': i\n",
    "        })\n",
    "\n",
    "    feature_importances['mean_importance'] = feature_importances.mean(axis=1)\n",
    "    feature_importances['std_importance'] = feature_importances.std(axis=1)\n",
    "    feature_importances = feature_importances.sort_values('mean_importance', ascending=False)\n",
    "    return cv_results, feature_importances, fold_aucs\n",
    "\n",
    "def plot_roc_curves_with_comparisons(tables_dict, metadata, pair_comparisons, n_splits=5):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "    color_map_skin = {\n",
    "        'skin-ADL_vs_skin-H': 'green',\n",
    "        'skin-ADNL_vs_skin-ADL': 'blue',\n",
    "        'skin-ADNL_vs_skin-H': 'purple'\n",
    "    }\n",
    "\n",
    "    all_feature_importances = {}\n",
    "    all_fold_aucs = {}\n",
    "\n",
    "    for label1, label2 in pair_comparisons:\n",
    "        comparison_key = f'{label1}_vs_{label2}'\n",
    "        all_feature_importances[comparison_key] = {}\n",
    "        all_fold_aucs[comparison_key] = {}\n",
    "\n",
    "        for table_name, table in tables_dict.items():\n",
    "            meta_subset = metadata[metadata['group'].isin([label1, label2])]\n",
    "            common_samples = table.index.intersection(meta_subset.index)\n",
    "            X = table.loc[common_samples]\n",
    "            meta_filtered = meta_subset.loc[common_samples]\n",
    "\n",
    "            if len(common_samples) < 10:\n",
    "                print(f\"Skipping {table_name} for {label1} vs {label2}: insufficient samples ({len(common_samples)})\")\n",
    "                continue\n",
    "\n",
    "            y = meta_filtered['group'].map({label1: 0, label2: 1})\n",
    "            groups = meta_filtered['pid']\n",
    "            cv_results, feature_imp, fold_aucs = run_group_stratified_cv(X, y, groups, n_splits=n_splits)\n",
    "\n",
    "            if len(cv_results) < 2:\n",
    "                print(f\"Skipping {table_name} for {label1} vs {label2}: CV returned insufficient results\")\n",
    "                continue\n",
    "\n",
    "            all_feature_importances[comparison_key][table_name] = feature_imp\n",
    "            all_fold_aucs[comparison_key][table_name] = fold_aucs\n",
    "\n",
    "            mean_fpr = np.linspace(0, 1, 100)\n",
    "            tprs, aucs = [], []\n",
    "            for result in cv_results:\n",
    "                tprs.append(interp(mean_fpr, result['fpr'], result['tpr']))\n",
    "                tprs[-1][0] = 0.0\n",
    "                aucs.append(result['auc'])\n",
    "\n",
    "            mean_tpr = np.mean(tprs, axis=0)\n",
    "            mean_tpr[-1] = 1.0\n",
    "            std_tpr = np.std(tprs, axis=0)\n",
    "            tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "            tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "            ax.plot(mean_fpr, mean_tpr, lw=2,\n",
    "                    label=f'{label1} vs {label2} (AUC = {np.mean(aucs):.2f} ± {np.std(aucs):.2f})',\n",
    "                    color=color_map_skin.get(comparison_key, 'grey'))\n",
    "            ax.fill_between(mean_fpr, tprs_lower, tprs_upper, alpha=0.3,\n",
    "                            color=color_map_skin.get(comparison_key, 'grey'))\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=14)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=14)\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.legend(loc='lower right', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    pairwise_comparisons = compute_pairwise_comparisons(all_fold_aucs)\n",
    "    return fig, all_feature_importances, pairwise_comparisons\n",
    "\n",
    "def compute_pairwise_comparisons(fold_aucs_dict):\n",
    "    results = []\n",
    "    for task, methods_dict in fold_aucs_dict.items():\n",
    "        methods = list(methods_dict.keys())\n",
    "        for method1, method2 in combinations(methods, 2):\n",
    "            aucs1, aucs2 = methods_dict[method1], methods_dict[method2]\n",
    "            min_len = min(len(aucs1), len(aucs2))\n",
    "            if min_len < 2:\n",
    "                continue\n",
    "            aucs1, aucs2 = aucs1[:min_len], aucs2[:min_len]\n",
    "            try:\n",
    "                _, p_wilcoxon = wilcoxon(aucs1, aucs2)\n",
    "            except:\n",
    "                p_wilcoxon = np.nan\n",
    "            _, p_ttest = ttest_rel(aucs1, aucs2)\n",
    "            results.append({\n",
    "                'Task': task,\n",
    "                'Method 1': method1,\n",
    "                'Method 2': method2,\n",
    "                'Mean AUC 1': np.mean(aucs1),\n",
    "                'Mean AUC 2': np.mean(aucs2),\n",
    "                'AUC Difference': np.mean(aucs1) - np.mean(aucs2),\n",
    "                'p-value (Wilcoxon)': p_wilcoxon,\n",
    "                'p-value (t-test)': p_ttest,\n",
    "                'Significant (p<0.05)': (p_wilcoxon < 0.05) if not np.isnan(p_wilcoxon) else (p_ttest < 0.05)\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Sample execution\n",
    "tables = {'V4': df}\n",
    "comparisons = [('skin-ADL', 'skin-H'), ('skin-ADNL', 'skin-ADL'), ('skin-ADNL', 'skin-H')]\n",
    "n_cv_splits = 3\n",
    "\n",
    "fig, feature_importances, pairwise_stats = plot_roc_curves_with_comparisons(tables, metadata, comparisons, n_splits=n_cv_splits)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Pairwise Performance Comparison of Methods\")\n",
    "print(\"=\"*80)\n",
    "print(pairwise_stats.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "for comparison, data_types in feature_importances.items():\n",
    "    print(f\"\\n{'='*50}\\nTop 10 important features for {comparison}:\\n{'='*50}\")\n",
    "    for data_type, features_df in data_types.items():\n",
    "        print(f\"\\n{data_type}:\\n{'-'*40}\")\n",
    "        print(features_df[['mean_importance', 'std_importance']].head(10))\n",
    "\n",
    "plt.suptitle('Random Forest Classifications by 16S V4 ASVs', fontsize=16, y=1.02)\n",
    "plt.savefig('../Plots/Analysis_figures/Random_Forest/rf_ASV_skin-groups-only.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Pairwise Performance Comparison of Methods\n",
      "================================================================================\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "==================================================\n",
      "Top 10 important features for nares-AD_vs_nares-H:\n",
      "==================================================\n",
      "\n",
      "V4:\n",
      "----------------------------------------\n",
      "                                                    mean_importance  \\\n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.027070   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.022989   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAAT...         0.021538   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGACAAGCGTTGTCCGGATT...         0.021311   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.019339   \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...         0.017363   \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...         0.017226   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...         0.015726   \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...         0.012700   \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...         0.012563   \n",
      "\n",
      "                                                    std_importance  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.006143  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.000278  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGGTGCAAGCGTTGTCCGGAAT...        0.002732  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGACAAGCGTTGTCCGGATT...        0.001228  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.007307  \n",
      "GTGCCAGCAGCCGCGGTAATACGGAGGGTGCGAGCGTTAATCGGAAT...        0.002012  \n",
      "GTGCCAGCAGCCGCGGTGATACGTAGGGTGCGAGCGTTGTCCGGATT...        0.002276  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATT...        0.000797  \n",
      "GTGCCAGCCGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAAT...        0.000467  \n",
      "GTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTGTCCGGAAT...        0.001777  \n"
     ]
    }
   ],
   "source": [
    "# Set overall styling for plots\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "# Custom function for group-stratified k-fold\n",
    "def group_stratified_kfold(X, y, groups, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Custom implementation of cross-validation that respects both groups and stratification\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Feature matrix\n",
    "    y : Series\n",
    "        Target labels\n",
    "    groups : Series\n",
    "        Group labels for samples (e.g., pid)\n",
    "    n_splits : int\n",
    "        Number of folds\n",
    "    random_state : int\n",
    "        Random seed\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples\n",
    "        Each tuple contains (train_indices, test_indices)\n",
    "    \"\"\"\n",
    "    # Get unique groups\n",
    "    unique_groups = np.unique(groups)\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(unique_groups)\n",
    "    \n",
    "    # Create label distribution per group\n",
    "    group_label_dist = {}\n",
    "    for group in unique_groups:\n",
    "        group_mask = groups == group\n",
    "        group_y = y[group_mask]\n",
    "        group_label_dist[group] = {label: np.sum(group_y == label) for label in np.unique(y)}\n",
    "    \n",
    "    # Initialize folds with empty lists\n",
    "    folds = [[] for _ in range(n_splits)]\n",
    "    \n",
    "    # Track current distribution of labels in each fold\n",
    "    fold_label_dist = [{label: 0 for label in np.unique(y)} for _ in range(n_splits)]\n",
    "    \n",
    "    # Sort groups by size (number of samples) in descending order to place larger groups first\n",
    "    sorted_groups = sorted(unique_groups, key=lambda g: sum(groups == g), reverse=True)\n",
    "    \n",
    "    # Assign groups to folds\n",
    "    for group in sorted_groups:\n",
    "        # Calculate which fold would benefit most from this group\n",
    "        # by minimizing the imbalance across all labels\n",
    "        best_fold = 0\n",
    "        min_imbalance = float('inf')\n",
    "        \n",
    "        group_size = sum(groups == group)\n",
    "        \n",
    "        for fold_idx in range(n_splits):\n",
    "            # Calculate current imbalance if we add this group\n",
    "            temp_fold_dist = fold_label_dist[fold_idx].copy()\n",
    "            for label, count in group_label_dist[group].items():\n",
    "                temp_fold_dist[label] += count\n",
    "            \n",
    "            # Calculate imbalance as variance of label proportions\n",
    "            fold_size = sum(temp_fold_dist.values())\n",
    "            if fold_size == 0:\n",
    "                proportions = [0] * len(temp_fold_dist)\n",
    "            else:\n",
    "                proportions = [count / fold_size for count in temp_fold_dist.values()]\n",
    "            \n",
    "            imbalance = np.var(proportions) + fold_size / (sum(groups.shape) / n_splits)\n",
    "            \n",
    "            if imbalance < min_imbalance:\n",
    "                min_imbalance = imbalance\n",
    "                best_fold = fold_idx\n",
    "        \n",
    "        # Assign group to best fold\n",
    "        folds[best_fold].extend(np.where(groups == group)[0])\n",
    "        # Update fold distribution\n",
    "        for label, count in group_label_dist[group].items():\n",
    "            fold_label_dist[best_fold][label] += count\n",
    "    \n",
    "    # Create train/test indices\n",
    "    train_test_indices = []\n",
    "    for i in range(n_splits):\n",
    "        test_idx = np.array(folds[i])\n",
    "        train_idx = np.concatenate([folds[j] for j in range(n_splits) if j != i])\n",
    "        train_test_indices.append((train_idx, test_idx))\n",
    "    \n",
    "    return train_test_indices\n",
    "\n",
    "# Modified function to run group-stratified cross-validation with feature importance\n",
    "def run_group_stratified_cv(X, y, groups, n_splits=5):\n",
    "    # Get group-stratified folds\n",
    "    folds = group_stratified_kfold(X, y, groups, n_splits=n_splits)\n",
    "    \n",
    "    # Initialize arrays to store results\n",
    "    cv_results = []\n",
    "    feature_importances = pd.DataFrame(index=X.columns)\n",
    "    fold_aucs = []\n",
    "    \n",
    "    # Run cross-validation\n",
    "    for i, (train_idx, test_idx) in enumerate(folds):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # Handle cases where train set might contain only one class\n",
    "        if len(np.unique(y_train)) < 2 or len(np.unique(y_test)) < 2:\n",
    "            print(f\"Skipping fold {i+1} due to insufficient class representation\")\n",
    "            continue\n",
    "            \n",
    "        # Train classifier\n",
    "        clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        probas = clf.predict_proba(X_test)\n",
    "        \n",
    "        # Store feature importance for this fold\n",
    "        feature_importances[f'fold_{i}'] = clf.feature_importances_\n",
    "        \n",
    "        # Store results\n",
    "        fpr, tpr, _ = roc_curve(y_test, probas[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        fold_aucs.append(roc_auc)\n",
    "        \n",
    "        cv_results.append({\n",
    "            'y_true': y_test,\n",
    "            'y_proba': probas[:, 1],\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr,\n",
    "            'auc': roc_auc,\n",
    "            'fold': i\n",
    "        })\n",
    "    \n",
    "    # Calculate mean feature importance across folds\n",
    "    feature_importances['mean_importance'] = feature_importances.mean(axis=1)\n",
    "    feature_importances['std_importance'] = feature_importances.std(axis=1)\n",
    "    feature_importances = feature_importances.sort_values('mean_importance', ascending=False)\n",
    "    \n",
    "    return cv_results, feature_importances, fold_aucs\n",
    "\n",
    "# Function to compute and plot ROC curves with error bars plus perform pairwise comparisons\n",
    "def plot_roc_curves_with_comparisons(tables_dict, metadata, pair_comparisons, n_splits=5):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "    color_map = {\n",
    "        'skin-ADL_vs_skin-H': '#4343a3',\n",
    "        'skin-ADNL_vs_skin-ADL': '#6ab2bd',\n",
    "        'skin-ADNL_vs_skin-H': '#dd7966',\n",
    "        'nares-AD_vs_nares-H': 'orange'\n",
    "    }\n",
    "\n",
    "    all_feature_importances = {}\n",
    "    all_fold_aucs = {}\n",
    "\n",
    "    for label1, label2 in pair_comparisons:\n",
    "        comparison_key = f'{label1}_vs_{label2}'\n",
    "        all_feature_importances[comparison_key] = {}\n",
    "        all_fold_aucs[comparison_key] = {}\n",
    "\n",
    "        for table_name, table in tables_dict.items():\n",
    "            meta_subset = metadata[metadata['group'].isin([label1, label2])]\n",
    "            common_samples = table.index.intersection(meta_subset.index)\n",
    "            X = table.loc[common_samples]\n",
    "            meta_filtered = meta_subset.loc[common_samples]\n",
    "\n",
    "            if len(common_samples) < 10:\n",
    "                print(f\"Skipping {table_name} for {label1} vs {label2}: insufficient samples ({len(common_samples)})\")\n",
    "                continue\n",
    "\n",
    "            y = meta_filtered['group'].map({label1: 0, label2: 1})\n",
    "            groups = meta_filtered['pid']\n",
    "            cv_results, feature_imp, fold_aucs = run_group_stratified_cv(X, y, groups, n_splits=n_splits)\n",
    "            all_feature_importances[comparison_key][table_name] = feature_imp\n",
    "            all_fold_aucs[comparison_key][table_name] = fold_aucs\n",
    "\n",
    "            if len(cv_results) < 2:\n",
    "                print(f\"Skipping {table_name} for {label1} vs {label2}: CV returned insufficient results\")\n",
    "                continue\n",
    "\n",
    "            mean_fpr = np.linspace(0, 1, 100)\n",
    "            tprs, aucs = [], []\n",
    "            for result in cv_results:\n",
    "                tprs.append(np.interp(mean_fpr, result['fpr'], result['tpr']))\n",
    "                tprs[-1][0] = 0.0\n",
    "                aucs.append(result['auc'])\n",
    "\n",
    "            mean_tpr = np.mean(tprs, axis=0)\n",
    "            mean_tpr[-1] = 1.0\n",
    "            std_tpr = np.std(tprs, axis=0)\n",
    "            tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "            tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "            plot_color = color_map.get(comparison_key, 'gray')\n",
    "\n",
    "            ax.plot(mean_fpr, mean_tpr, lw=2,\n",
    "                    label=f'{label1} vs {label2} (AUC = {np.mean(aucs):.2f} ± {np.std(aucs):.2f})',\n",
    "                    color=plot_color)\n",
    "            ax.fill_between(mean_fpr, tprs_lower, tprs_upper, alpha=0.3, color=plot_color)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=14)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=14)\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.legend(loc='lower right', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    pairwise_comparisons = compute_pairwise_comparisons(all_fold_aucs)\n",
    "    return fig, all_feature_importances, pairwise_comparisons\n",
    "\n",
    "\n",
    "# Function to perform pairwise statistical tests\n",
    "def compute_pairwise_comparisons(fold_aucs_dict):\n",
    "    \"\"\"\n",
    "    Perform pairwise statistical tests between methods for each task\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fold_aucs_dict : dict\n",
    "        Dictionary with fold-wise AUC values for each method\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Table with pairwise comparisons and p-values\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for task, methods_dict in fold_aucs_dict.items():\n",
    "        # Get list of methods that have AUC values\n",
    "        methods = list(methods_dict.keys())\n",
    "        \n",
    "        # Perform pairwise comparisons\n",
    "        for method1, method2 in combinations(methods, 2):\n",
    "            # Get AUC values for both methods\n",
    "            aucs1 = methods_dict[method1]\n",
    "            aucs2 = methods_dict[method2]\n",
    "            \n",
    "            # Ensure equal length (use only common folds)\n",
    "            min_len = min(len(aucs1), len(aucs2))\n",
    "            if min_len < 2:\n",
    "                continue\n",
    "                \n",
    "            aucs1 = aucs1[:min_len]\n",
    "            aucs2 = aucs2[:min_len]\n",
    "            \n",
    "            # Calculate mean AUCs\n",
    "            mean_auc1 = np.mean(aucs1)\n",
    "            mean_auc2 = np.mean(aucs2)\n",
    "            diff_auc = mean_auc1 - mean_auc2\n",
    "            \n",
    "            # Perform statistical tests\n",
    "            # Wilcoxon signed-rank test (non-parametric)\n",
    "            try:\n",
    "                _, p_wilcoxon = wilcoxon(aucs1, aucs2)\n",
    "            except:\n",
    "                p_wilcoxon = np.nan\n",
    "                \n",
    "            # Paired t-test (parametric)\n",
    "            _, p_ttest = ttest_rel(aucs1, aucs2)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'Task': task,\n",
    "                'Method 1': method1,\n",
    "                'Method 2': method2,\n",
    "                'Mean AUC 1': mean_auc1,\n",
    "                'Mean AUC 2': mean_auc2,\n",
    "                'AUC Difference': diff_auc,\n",
    "                'p-value (Wilcoxon)': p_wilcoxon,\n",
    "                'p-value (t-test)': p_ttest,\n",
    "                'Significant (p<0.05)': (p_wilcoxon < 0.05) if not np.isnan(p_wilcoxon) else (p_ttest < 0.05)\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Create a dictionary of tables\n",
    "tables = {\n",
    "    'V4': df\n",
    "}\n",
    "\n",
    "# Define pairwise comparisons\n",
    "comparisons = [('nares-AD', 'nares-H')]\n",
    "\n",
    "\n",
    "# Set number of CV splits\n",
    "n_cv_splits = 3\n",
    "\n",
    "# Run analysis and plot\n",
    "fig, feature_importances, pairwise_stats = plot_roc_curves_with_comparisons(tables, metadata, comparisons, n_splits=n_cv_splits)\n",
    "\n",
    "# Display pairwise performance comparison table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Pairwise Performance Comparison of Methods\")\n",
    "print(\"=\"*80)\n",
    "print(pairwise_stats.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# Display the top 10 most important features for each comparison and data type\n",
    "for comparison, data_types in feature_importances.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Top 10 important features for {comparison}:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    for data_type, features_df in data_types.items():\n",
    "        print(f\"\\n{data_type}:\")\n",
    "        print(\"-\" * 40)\n",
    "        top_features = features_df.sort_values('mean_importance', ascending=False).head(10)\n",
    "        print(top_features[['mean_importance', 'std_importance']])\n",
    "\n",
    "# Add supertitle to the plot\n",
    "plt.suptitle('Random Forest Classification by 16S V4 ASVs', fontsize=18, y=1.02)\n",
    "\n",
    "plt.savefig('../Plots/Analysis_figures/Random_Forest/rf_ASV__nares-groups-only.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiime2-metagenome-2024.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
